{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNypLDICHw0qz8u274xnpjn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lihiShlomit/DSproject/blob/main/Copy_of_Copy_of_trainYolo2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5DUJWl-hMZPG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "rm -rf /content/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpfjqXGIPy0u",
        "outputId": "db556453-bdae-4729-d26f-62118241fb14",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17516, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 17516 (delta 7), reused 0 (delta 0), pack-reused 17496 (from 4)\u001b[K\n",
            "Receiving objects: 100% (17516/17516), 16.66 MiB | 16.64 MiB/s, done.\n",
            "Resolving deltas: 100% (11998/11998), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "print(\"sys.path:\")\n",
        "for p in sys.path:\n",
        "    print(p)\n",
        "\n",
        "print(\"\\nתוכן /content/yolov5:\")\n",
        "print(os.listdir('/content/yolov5'))\n",
        "\n",
        "print(\"\\nתוכן /content/yolov5/models:\")\n",
        "print(os.listdir('/content/yolov5/models'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhNAJZQgHvb9",
        "outputId": "e3d3a5e5-d26b-4541-87f4-603fc186b11d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sys.path:\n",
            "/content/yolov5\n",
            "/content\n",
            "/env/python\n",
            "/usr/lib/python311.zip\n",
            "/usr/lib/python3.11\n",
            "/usr/lib/python3.11/lib-dynload\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages\n",
            "/usr/lib/python3/dist-packages\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/extensions\n",
            "/root/.ipython\n",
            "/content/yolov5\n",
            "/content/yolov5\n",
            "/content/yolov5\n",
            "\n",
            "תוכן /content/yolov5:\n",
            "['README.zh-CN.md', 'data', '.dockerignore', 'pyproject.toml', 'detect.py', 'README.md', 'CITATION.cff', 'hubconf.py', 'models', 'CONTRIBUTING.md', 'utils', 'train.py', 'export.py', 'classify', '.git', 'LICENSE', 'segment', 'tutorial.ipynb', 'val.py', 'benchmarks.py', 'requirements.txt', '.gitignore', '.github', '.gitattributes']\n",
            "\n",
            "תוכן /content/yolov5/models:\n",
            "['yolov5n.yaml', 'yolov5m.yaml', 'experimental.py', 'yolov5l.yaml', '__init__.py', 'yolo.py', 'common.py', 'tf.py', 'segment', 'hub', 'yolov5s.yaml', 'yolov5x.yaml']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists('/content/yolov5/utils/datasets.py'))  # Should now be True"
      ],
      "metadata": {
        "id": "zIbJreqVQ14c",
        "outputId": "491d4a08-a75f-42ca-d6bf-d3c5104a272e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/yolov5/utils/"
      ],
      "metadata": {
        "id": "zkuXYkMIQ8PJ",
        "outputId": "aabab976-9997-4653-9cd4-75e27f30e65f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activations.py\t  callbacks.py\t  general.py\t     metrics.py\n",
            "augmentations.py  dataloaders.py  google_app_engine  plots.py\n",
            "autoanchor.py\t  docker\t  __init__.py\t     segment\n",
            "autobatch.py\t  downloads.py\t  loggers\t     torch_utils.py\n",
            "aws\t\t  flask_rest_api  loss.py\t     triton.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/yolov5')\n",
        "\n",
        "import torch\n",
        "from models.yolo import Model\n",
        "from utils.dataloaders import create_dataloader\n",
        "from utils.general import check_dataset\n",
        "from utils.torch_utils import select_device\n",
        "from utils.loss import ComputeLoss\n",
        "from pathlib import Path\n",
        "import os\n",
        "from utils.general import non_max_suppression\n",
        "from utils.metrics import bbox_iou\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from utils.dataloaders import LoadImagesAndLabels\n",
        "\n",
        "# import os\n",
        "# os.environ['RANK'] = '-1'\n",
        "# os.environ['WORLD_SIZE'] = '1'\n",
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "-ec1xkjYPGxd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "cd9d27a7-6f28-4e90-f842-7672a9fd11af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'models'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-1601370683.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneral\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_YAML_PATH = \"/content/drive/MyDrive/project/data/license_plates/archive/dataset.yaml\"\n",
        "\n",
        "data = check_dataset(DATA_YAML_PATH)\n",
        "train_path = data['train']\n",
        "val_path = data['val']\n",
        "test_path = data['test']\n",
        "nc = data['nc']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvktHhL-PHD1",
        "outputId": "4a724532-74c4-4854-bf0b-801f8df5786f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_collate_fn(batch):\n",
        "    imgs, targets, paths, shapes = zip(*batch)\n",
        "    imgs = torch.stack(imgs, dim=0)\n",
        "\n",
        "    # שלב את כל ה-targets לטנזור אחד, והוסף אינדקס תמונה בעמודה 0\n",
        "    for i, t in enumerate(targets):\n",
        "        t[:, 0] = i  # קוד YOLO מצפה לעמודה 0 עם אינדקס התמונה\n",
        "    targets = torch.cat(targets, dim=0)\n",
        "\n",
        "    return imgs, targets, paths, shapes"
      ],
      "metadata": {
        "id": "WChb6gTtFAIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hyp = {\n",
        "    'mosaic': 1.0,          # הפעלת mosaic augmentation\n",
        "    'mixup': 0.1,           # הפעלת mixup\n",
        "    'lr0': 0.001,\n",
        "    'momentum': 0.9,\n",
        "    'weight_decay': 0.0005,\n",
        "    'warmup_epochs': 3.0,\n",
        "    'warmup_momentum': 0.8,\n",
        "    'warmup_bias_lr': 0.1,\n",
        "    'box': 0.05,\n",
        "    'cls': 0.5,\n",
        "    'obj': 1.0,\n",
        "    'anchor_t': 4.0,\n",
        "    'fl_gamma': 0.0,\n",
        "    'hsv_h': 0.015,\n",
        "    'hsv_s': 0.7,\n",
        "    'hsv_v': 0.4,\n",
        "    'degrees': 5.0,          # סיבוב עד 5 מעלות\n",
        "    'translate': 0.1,\n",
        "    'scale': 0.5,\n",
        "    'shear': 2.0,            # טיהוי קל\n",
        "    'perspective': 0.001,    # קצת פרספקטיבה\n",
        "    'flipud': 0.1,           # הפעלת flip up-down 10%\n",
        "    'fliplr': 0.5,\n",
        "    'copy_paste': 0.0,\n",
        "    'cls_pw': 1.0,\n",
        "    'obj_pw': 1.0\n",
        "}\n",
        "\n",
        "cfg = '/content/yolov5/models/yolov5s.yaml'\n",
        "nc = 1\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = Model(cfg, ch=3, nc=nc).to(device)\n",
        "\n",
        "imgsz = 640\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = LoadImagesAndLabels(train_path, imgsz, augment=True, hyp=hyp)\n",
        "val_dataset = LoadImagesAndLabels(val_path, imgsz, augment=False, hyp=hyp)\n",
        "test_dataset = LoadImagesAndLabels(test_path, imgsz, augment=False, hyp=hyp)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=4, collate_fn=yolo_collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        num_workers=4, collate_fn=yolo_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                         num_workers=4, collate_fn=yolo_collate_fn)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyp['lr0'],\n",
        "                             betas=(0.9, 0.999), weight_decay=hyp['weight_decay'])\n",
        "\n",
        "model.hyp = hyp\n",
        "compute_loss = ComputeLoss(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8h4Rbc7PHMz",
        "outputId": "15f2b762-ddd0-4763-d662-4f35f2712cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "Scanning /content/drive/MyDrive/project/data/license_plates/archive/labels/train_split.cache... 1220 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1220/1220 [00:00<?, ?it/s]\n",
            "Scanning /content/drive/MyDrive/project/data/license_plates/archive/labels/val.cache... 306 images, 0 backgrounds, 0 corrupt: 100%|██████████| 306/306 [00:00<?, ?it/s]\n",
            "Scanning /content/drive/MyDrive/project/data/license_plates/archive/labels/test.cache... 169 images, 0 backgrounds, 0 corrupt: 100%|██████████| 169/169 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, targets, paths, _ in train_loader:\n",
        "        imgs = imgs.to(device).float() / 255.0\n",
        "        targets = targets.to(device)\n",
        "        pred = model(imgs)\n",
        "        loss, _ = compute_loss(pred, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs} - Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # --- VALIDATION ---\n",
        "    model.eval()\n",
        "    val_loss_total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets, paths, _ in val_loader:\n",
        "            imgs = imgs.to(device).float() / 255.0\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            pred = model(imgs)\n",
        "            loss, _ = compute_loss(pred[1], targets)\n",
        "            val_loss_total += loss.item()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    avg_val_loss = val_loss_total / len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/project/model_16_20_001.pth')"
      ],
      "metadata": {
        "id": "gd-FBEtPDipA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9a9356-437f-48b6-d102-c9ccd636acab",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20 - Train Loss: 1.7275\n",
            "Epoch 1/20 - Val Loss: 1.7542\n",
            "\n",
            "Epoch 2/20 - Train Loss: 1.4055\n",
            "Epoch 2/20 - Val Loss: 1.1484\n",
            "\n",
            "Epoch 3/20 - Train Loss: 1.2330\n",
            "Epoch 3/20 - Val Loss: 0.8804\n",
            "\n",
            "Epoch 4/20 - Train Loss: 1.1252\n",
            "Epoch 4/20 - Val Loss: 0.9473\n",
            "\n",
            "Epoch 5/20 - Train Loss: 1.0569\n",
            "Epoch 5/20 - Val Loss: 0.9046\n",
            "\n",
            "Epoch 6/20 - Train Loss: 1.0321\n",
            "Epoch 6/20 - Val Loss: 0.8706\n",
            "\n",
            "Epoch 7/20 - Train Loss: 0.9729\n",
            "Epoch 7/20 - Val Loss: 0.6634\n",
            "\n",
            "Epoch 8/20 - Train Loss: 0.9436\n",
            "Epoch 8/20 - Val Loss: 0.6142\n",
            "\n",
            "Epoch 9/20 - Train Loss: 0.8922\n",
            "Epoch 9/20 - Val Loss: 0.8056\n",
            "\n",
            "Epoch 10/20 - Train Loss: 0.8786\n",
            "Epoch 10/20 - Val Loss: 0.7392\n",
            "\n",
            "Epoch 11/20 - Train Loss: 0.8714\n",
            "Epoch 11/20 - Val Loss: 0.8605\n",
            "\n",
            "Epoch 12/20 - Train Loss: 0.8603\n",
            "Epoch 12/20 - Val Loss: 0.8251\n",
            "\n",
            "Epoch 13/20 - Train Loss: 0.8524\n",
            "Epoch 13/20 - Val Loss: 0.9199\n",
            "\n",
            "Epoch 14/20 - Train Loss: 0.8282\n",
            "Epoch 14/20 - Val Loss: 0.6724\n",
            "\n",
            "Epoch 15/20 - Train Loss: 0.8120\n",
            "Epoch 15/20 - Val Loss: 0.6970\n",
            "\n",
            "Epoch 16/20 - Train Loss: 0.8097\n",
            "Epoch 16/20 - Val Loss: 0.6377\n",
            "\n",
            "Epoch 17/20 - Train Loss: 0.8033\n",
            "Epoch 17/20 - Val Loss: 0.6919\n",
            "\n",
            "Epoch 18/20 - Train Loss: 0.8071\n",
            "Epoch 18/20 - Val Loss: 0.5861\n",
            "\n",
            "Epoch 19/20 - Train Loss: 0.7932\n",
            "Epoch 19/20 - Val Loss: 0.6260\n",
            "\n",
            "Epoch 20/20 - Train Loss: 0.7912\n",
            "Epoch 20/20 - Val Loss: 0.6453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yolov5 import YOLOv5\n",
        "# 1. מגדירים את המודל (או מייבאים אותו)\n",
        "model = YOLOv5('yolov5s.pt', device=device)\n",
        "\n",
        "# 2. טוענים משקלים\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/project/model_16_20_001.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "VJO_UX5NFwrm",
        "outputId": "48b0eba4-f5b6-4e5c-b186-f01c351ed056"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'YOLOv5' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-2594808524.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. מגדירים את המודל (או מייבאים אותו)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov5s.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 2. טוענים משקלים\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/project/model_16_20_001.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'YOLOv5' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def validate(model, dataloader, device, iou_thres=0.5, conf_thres=0.001):\n",
        "    model.eval()\n",
        "    stats = []  # לאיסוף: (correct, confs, pred_classes, target_classes)\n",
        "\n",
        "    for imgs, targets, paths, shapes in dataloader:\n",
        "        imgs = imgs.to(device).float() / 255.0\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(imgs)\n",
        "            preds = non_max_suppression(preds, conf_thres=conf_thres, iou_thres=0.6)\n",
        "\n",
        "        for pred in preds:\n",
        "            if pred is None:\n",
        "                continue\n",
        "\n",
        "            correct = torch.zeros(pred.shape[0], dtype=torch.bool, device=device)\n",
        "\n",
        "            # כל התוויות ב-batch (במקרה שאין אינדקס תמונה)\n",
        "            labels = targets\n",
        "\n",
        "            if labels.size(0):\n",
        "                for ti, t in enumerate(labels):\n",
        "                    t_box = t[1:5].unsqueeze(0)   # bbox של תווית\n",
        "                    t_cls = t[0]                 # class id של תווית\n",
        "\n",
        "                    for pi, p in enumerate(pred):\n",
        "                        if correct[pi]:\n",
        "                            continue\n",
        "                        p_box = p[0:4].unsqueeze(0)  # bbox תחזית\n",
        "                        p_cls = p[5]                 # class id תחזית\n",
        "\n",
        "                        iou = bbox_iou(t_box, p_box)\n",
        "                        if iou > iou_thres and p_cls == t_cls:\n",
        "                            correct[pi] = True\n",
        "\n",
        "            stats.append((\n",
        "                correct.cpu(),\n",
        "                pred[:, 4].cpu(),  # confidence\n",
        "                pred[:, 5].cpu(),  # class pred\n",
        "                labels[:, 0].cpu() # class target\n",
        "            ))\n",
        "\n",
        "    # איחוד כל הסטטיסטיקות\n",
        "    stats = [np.concatenate(x, 0) for x in zip(*stats)] if stats else [np.array([])]*4\n",
        "\n",
        "    if len(stats) and stats[0].any():\n",
        "        p, r, ap, f1, _ = ap_per_class(*stats)\n",
        "        print(f\"Precision: {p.mean():.4f}, Recall: {r.mean():.4f}, mAP@0.5: {ap.mean():.4f}\")\n",
        "        return p, r, ap, f1\n",
        "    else:\n",
        "        print(\"No valid predictions for mAP calculation\")\n",
        "        return None\n",
        "\n",
        "\n",
        "validate(model, val_loader, device)"
      ],
      "metadata": {
        "id": "V5pUKKNnDl0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32f176c-3230-4485-98cc-476c0654f693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No valid predictions for mAP calculation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "gMWqVnFuc7la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import torch\n",
        "\n",
        "# שמירה של ה-state_dict של המודל עם joblib\n",
        "joblib.dump(model.state_dict(), 'yolov5_model.pkl')"
      ],
      "metadata": {
        "id": "k_hZewTgTHhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import torch\n",
        "from models.yolo import Model  # ודא שאתה מייבא את המודל בצורה נכונה\n",
        "\n",
        "# יצירת המודל מחדש עם אותם פרמטרים\n",
        "cfg = 'models/yolov5s.yaml'  # הקובץ שלך\n",
        "nc = 1  # מספר המחלקות שלך\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = Model(cfg, ch=3, nc=nc).to(device)\n",
        "\n",
        "# טעינת ה-state_dict של המודל עם joblib\n",
        "model.load_state_dict(joblib.load('yolov5_model.pkl'))\n",
        "\n",
        "# הפיכת המודל למצב של אימות\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# חיזוי על נתונים חדשים (כמו תמונה שהכנת מראש)\n",
        "with torch.no_grad():  # לא צריך לחשב גרדיאנטים בזמן החיזוי\n",
        "    predictions = model(input_images)  # תחזור כאן על חיזוי על תמונה\n",
        "\n",
        "\n",
        "# הערכת ביצועי המודל על נתוני בדיקה\n",
        "validate(model, test_loader, device)"
      ],
      "metadata": {
        "id": "S2WSE9M5S_Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_debug(model, dataloader, device, iou_thres=0.5, conf_thres=0.25, max_batches=2):\n",
        "    model.eval()\n",
        "    printed = 0\n",
        "\n",
        "    for batch_i, (imgs, targets, paths, shapes) in enumerate(dataloader):\n",
        "        imgs = imgs.to(device).float() / 255.0\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(imgs)\n",
        "            preds = non_max_suppression(preds, conf_thres=conf_thres, iou_thres=iou_thres)\n",
        "\n",
        "        for i, pred in enumerate(preds):\n",
        "            if pred is None:\n",
        "                print(f\"\\nImage {paths[i] if paths else i}: No predictions\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nImage {paths[i] if paths else i}:\")\n",
        "            print(\"Ground Truth:\")\n",
        "            gt = targets  # אם אין אינדקס תמונה – כך\n",
        "            for t in gt:\n",
        "                print(f\"  Class: {int(t[0])}, BBox: {t[1:].tolist()}\")\n",
        "\n",
        "            print(\"Predictions:\")\n",
        "            for p in pred:\n",
        "                bbox = p[0:4].tolist()\n",
        "                conf = float(p[4])\n",
        "                cls = int(p[5])\n",
        "                print(f\"  Class: {cls}, Conf: {conf:.2f}, BBox: {bbox}\")\n",
        "\n",
        "            printed += 1\n",
        "            if printed >= max_batches:\n",
        "                return\n",
        "validate_debug(model, val_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "2zizapvAFixH",
        "outputId": "f82d3373-7793-4b8e-b101-19409bfc6094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1860337635.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprinted\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mvalidate_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}