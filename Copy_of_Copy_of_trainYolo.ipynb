{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjXPyJsIyo8uytZ3ufzx2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lihiShlomit/DSproject/blob/main/Copy_of_Copy_of_trainYolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5DUJWl-hMZPG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "rm -rf /content/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpfjqXGIPy0u",
        "outputId": "ea4c46e3-5dd9-4bb6-a34f-059a3535d61b",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17516, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 17516 (delta 6), reused 0 (delta 0), pack-reused 17497 (from 4)\u001b[K\n",
            "Receiving objects: 100% (17516/17516), 16.66 MiB | 13.58 MiB/s, done.\n",
            "Resolving deltas: 100% (11997/11997), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists('/content/yolov5/utils/datasets.py'))  # Should now be True"
      ],
      "metadata": {
        "id": "zIbJreqVQ14c",
        "outputId": "2529486b-d358-4170-f277-4ecc2eca66a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/yolov5/utils/"
      ],
      "metadata": {
        "id": "zkuXYkMIQ8PJ",
        "outputId": "86e50adc-4a4f-4a68-870f-d3e350442897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activations.py\t  callbacks.py\t  general.py\t     metrics.py\n",
            "augmentations.py  dataloaders.py  google_app_engine  plots.py\n",
            "autoanchor.py\t  docker\t  __init__.py\t     segment\n",
            "autobatch.py\t  downloads.py\t  loggers\t     torch_utils.py\n",
            "aws\t\t  flask_rest_api  loss.py\t     triton.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/yolov5')\n",
        "\n",
        "import torch\n",
        "from models.yolo import Model\n",
        "from utils.dataloaders import create_dataloader\n",
        "from utils.general import check_dataset\n",
        "from utils.torch_utils import select_device\n",
        "from utils.loss import ComputeLoss\n",
        "from pathlib import Path\n",
        "import os\n",
        "from utils.general import non_max_suppression\n",
        "from utils.metrics import bbox_iou\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from utils.dataloaders import LoadImagesAndLabels\n",
        "\n",
        "# import os\n",
        "# os.environ['RANK'] = '-1'\n",
        "# os.environ['WORLD_SIZE'] = '1'\n",
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "-ec1xkjYPGxd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_YAML_PATH = \"/content/drive/MyDrive/project/data/license_plates/archive/dataset.yaml\"\n",
        "\n",
        "data = check_dataset(DATA_YAML_PATH)\n",
        "train_path = data['train']\n",
        "val_path = data['val']\n",
        "test_path = data['test']\n",
        "nc = data['nc']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvktHhL-PHD1",
        "outputId": "5910ec3a-96ef-4726-b022-d0c9f3034929"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_collate_fn(batch):\n",
        "    imgs, targets, paths, shapes = zip(*batch)\n",
        "    imgs = torch.stack(imgs, dim=0)\n",
        "\n",
        "    # שלב את כל ה-targets לטנזור אחד, והוסף אינדקס תמונה בעמודה 0\n",
        "    for i, t in enumerate(targets):\n",
        "        t[:, 0] = i  # קוד YOLO מצפה לעמודה 0 עם אינדקס התמונה\n",
        "    targets = torch.cat(targets, dim=0)\n",
        "\n",
        "    return imgs, targets, paths, shapes"
      ],
      "metadata": {
        "id": "WChb6gTtFAIt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hyp = {\n",
        "    'mosaic': 0.0,\n",
        "    'mixup': 0.0,\n",
        "    'lr0': 0.001,\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'warmup_epochs': 3.0,\n",
        "    'warmup_momentum': 0.8,\n",
        "    'warmup_bias_lr': 0.1,\n",
        "    'box': 0.05,\n",
        "    'cls': 0.5,\n",
        "    'obj': 1.0,\n",
        "    'anchor_t': 4.0,\n",
        "    'fl_gamma': 0.0,\n",
        "    'hsv_h': 0.015,\n",
        "    'hsv_s': 0.7,\n",
        "    'hsv_v': 0.4,\n",
        "    'degrees': 0.0,\n",
        "    'translate': 0.1,\n",
        "    'scale': 0.5,\n",
        "    'shear': 0.0,\n",
        "    'perspective': 0.0,\n",
        "    'flipud': 0.0,\n",
        "    'fliplr': 0.5,\n",
        "\n",
        "\n",
        "    'copy_paste': 0.0,\n",
        "    'cls_pw': 1.0,\n",
        "    'obj_pw': 1.0\n",
        "}\n",
        "\n",
        "cfg = '/content/yolov5/models/yolov5s.yaml'\n",
        "nc = 1\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = Model(cfg, ch=3, nc=nc).to(device)\n",
        "\n",
        "imgsz = 640\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = LoadImagesAndLabels(train_path, imgsz, augment=True, hyp=hyp)\n",
        "val_dataset = LoadImagesAndLabels(val_path, imgsz, augment=False, hyp=hyp)\n",
        "test_dataset = LoadImagesAndLabels(test_path, imgsz, augment=False, hyp=hyp)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=4, collate_fn=yolo_collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        num_workers=4, collate_fn=yolo_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                         num_workers=4, collate_fn=yolo_collate_fn)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyp['lr0'],\n",
        "                             betas=(0.9, 0.999), weight_decay=hyp['weight_decay'])\n",
        "\n",
        "model.hyp = hyp\n",
        "compute_loss = ComputeLoss(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8h4Rbc7PHMz",
        "outputId": "5a3c4f0c-2f01-4521-e510-5a9cba54b728"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "Scanning /content/drive/MyDrive/project/data/license_plates/archive/labels/train_split.cache... 1220 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1220/1220 [00:00<?, ?it/s]\n",
            "Scanning /content/drive/MyDrive/project/data/license_plates/archive/labels/val.cache... 306 images, 0 backgrounds, 0 corrupt: 100%|██████████| 306/306 [00:00<?, ?it/s]\n",
            "Scanning /content/drive/MyDrive/project/data/license_plates/archive/labels/test.cache... 169 images, 0 backgrounds, 0 corrupt: 100%|██████████| 169/169 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, targets, paths, _ in train_loader:\n",
        "        imgs = imgs.to(device).float() / 255.0\n",
        "        targets = targets.to(device)\n",
        "        pred = model(imgs)\n",
        "        loss, _ = compute_loss(pred, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs} - Train Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "gd-FBEtPDipA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41955272-d7e3-4046-de25-7358ba8bf3c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10 - Train Loss: 1.5688\n",
            "\n",
            "Epoch 2/10 - Train Loss: 1.2069\n",
            "\n",
            "Epoch 3/10 - Train Loss: 1.0398\n",
            "\n",
            "Epoch 4/10 - Train Loss: 0.9533\n",
            "\n",
            "Epoch 5/10 - Train Loss: 0.9237\n",
            "\n",
            "Epoch 6/10 - Train Loss: 0.8918\n",
            "\n",
            "Epoch 7/10 - Train Loss: 0.8682\n",
            "\n",
            "Epoch 8/10 - Train Loss: 0.8244\n",
            "\n",
            "Epoch 9/10 - Train Loss: 0.8133\n",
            "\n",
            "Epoch 10/10 - Train Loss: 0.8084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def validate(model, dataloader, device, iou_thres=0.5, conf_thres=0.001):\n",
        "    model.eval()\n",
        "    stats = []  # לאיסוף: (correct, confs, pred_classes, target_classes)\n",
        "\n",
        "    for imgs, targets, paths, shapes in dataloader:\n",
        "        imgs = imgs.to(device).float() / 255.0\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(imgs)\n",
        "            preds = non_max_suppression(preds, conf_thres=conf_thres, iou_thres=0.6)\n",
        "\n",
        "        for pred in preds:\n",
        "            if pred is None:\n",
        "                continue\n",
        "\n",
        "            correct = torch.zeros(pred.shape[0], dtype=torch.bool, device=device)\n",
        "\n",
        "            # כל התוויות ב-batch (במקרה שאין אינדקס תמונה)\n",
        "            labels = targets\n",
        "\n",
        "            if labels.size(0):\n",
        "                for ti, t in enumerate(labels):\n",
        "                    t_box = t[1:5].unsqueeze(0)   # bbox של תווית\n",
        "                    t_cls = t[0]                 # class id של תווית\n",
        "\n",
        "                    for pi, p in enumerate(pred):\n",
        "                        if correct[pi]:\n",
        "                            continue\n",
        "                        p_box = p[0:4].unsqueeze(0)  # bbox תחזית\n",
        "                        p_cls = p[5]                 # class id תחזית\n",
        "\n",
        "                        iou = bbox_iou(t_box, p_box)\n",
        "                        if iou > iou_thres and p_cls == t_cls:\n",
        "                            correct[pi] = True\n",
        "\n",
        "            stats.append((\n",
        "                correct.cpu(),\n",
        "                pred[:, 4].cpu(),  # confidence\n",
        "                pred[:, 5].cpu(),  # class pred\n",
        "                labels[:, 0].cpu() # class target\n",
        "            ))\n",
        "\n",
        "    # איחוד כל הסטטיסטיקות\n",
        "    stats = [np.concatenate(x, 0) for x in zip(*stats)] if stats else [np.array([])]*4\n",
        "\n",
        "    if len(stats) and stats[0].any():\n",
        "        p, r, ap, f1, _ = ap_per_class(*stats)\n",
        "        print(f\"Precision: {p.mean():.4f}, Recall: {r.mean():.4f}, mAP@0.5: {ap.mean():.4f}\")\n",
        "        return p, r, ap, f1\n",
        "    else:\n",
        "        print(\"No valid predictions for mAP calculation\")\n",
        "        return None\n",
        "\n",
        "\n",
        "validate(model, val_loader, device)"
      ],
      "metadata": {
        "id": "V5pUKKNnDl0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32f176c-3230-4485-98cc-476c0654f693"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No valid predictions for mAP calculation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "gMWqVnFuc7la"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import torch\n",
        "\n",
        "# שמירה של ה-state_dict של המודל עם joblib\n",
        "joblib.dump(model.state_dict(), 'yolov5_model.pkl')"
      ],
      "metadata": {
        "id": "k_hZewTgTHhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import torch\n",
        "from models.yolo import Model  # ודא שאתה מייבא את המודל בצורה נכונה\n",
        "\n",
        "# יצירת המודל מחדש עם אותם פרמטרים\n",
        "cfg = 'models/yolov5s.yaml'  # הקובץ שלך\n",
        "nc = 1  # מספר המחלקות שלך\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = Model(cfg, ch=3, nc=nc).to(device)\n",
        "\n",
        "# טעינת ה-state_dict של המודל עם joblib\n",
        "model.load_state_dict(joblib.load('yolov5_model.pkl'))\n",
        "\n",
        "# הפיכת המודל למצב של אימות\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# חיזוי על נתונים חדשים (כמו תמונה שהכנת מראש)\n",
        "with torch.no_grad():  # לא צריך לחשב גרדיאנטים בזמן החיזוי\n",
        "    predictions = model(input_images)  # תחזור כאן על חיזוי על תמונה\n",
        "\n",
        "\n",
        "# הערכת ביצועי המודל על נתוני בדיקה\n",
        "validate(model, test_loader, device)"
      ],
      "metadata": {
        "id": "S2WSE9M5S_Qu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}