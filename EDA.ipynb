{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lihiShlomit/DSproject/blob/main/EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1-enSGi6bIc"
      },
      "outputs": [],
      "source": [
        "# @title Imports and connecting to drive\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Setting directories\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/project/data/license_plates/archive\"\n",
        "images_dir = os.path.join(base_path, \"images/train\")\n",
        "labels_dir = os.path.join(base_path, \"labels/train\")\n",
        "\n",
        "output_images_train = os.path.join(base_path, \"images/train_split\")\n",
        "output_images_val = os.path.join(base_path, \"images/val\")\n",
        "\n",
        "output_labels_train = os.path.join(base_path, \"labels/train_split\")\n",
        "output_labels_val = os.path.join(base_path, \"labels/val\")"
      ],
      "metadata": {
        "id": "Ap0iAHPM6dws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Function to create directories only if they're not already exist\n",
        "\n",
        "def make_clean_dir(path):\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path)"
      ],
      "metadata": {
        "id": "3BCHELj76fEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Creating directories\n",
        "\n",
        "make_clean_dir(output_images_train)\n",
        "make_clean_dir(output_images_val)\n",
        "make_clean_dir(output_labels_train)\n",
        "make_clean_dir(output_labels_val)"
      ],
      "metadata": {
        "id": "U1I-rjO_6fIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Splitting the train set into train set and validation set\n",
        "\n",
        "images = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Ts9RVusf6fNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Copying the relevant images and labels\n",
        "\n",
        "def copy_img_and_label(img_list, target_img_dir, target_lbl_dir):\n",
        "    for img_name in img_list:\n",
        "        name_no_ext = os.path.splitext(img_name)[0]\n",
        "        label_name = name_no_ext + \".txt\"\n",
        "\n",
        "        img_src = os.path.join(images_dir, img_name)\n",
        "        lbl_src = os.path.join(labels_dir, label_name)\n",
        "\n",
        "        img_dst = os.path.join(target_img_dir, img_name)\n",
        "        lbl_dst = os.path.join(target_lbl_dir, label_name)\n",
        "\n",
        "        shutil.copy2(img_src, img_dst)\n",
        "        if os.path.exists(lbl_src):\n",
        "            shutil.copy2(lbl_src, lbl_dst)\n",
        "\n",
        "copy_img_and_label(train_imgs, output_images_train, output_labels_train)\n",
        "copy_img_and_label(val_imgs, output_images_val, output_labels_val)"
      ],
      "metadata": {
        "id": "gxilQrc-6fTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Updating the yaml file to contain the relevant paths\n",
        "\n",
        "import yaml\n",
        "\n",
        "dataset_yaml_path = \"/content/drive/MyDrive/project/data/license_plates/archive/dataset.yaml\"\n",
        "\n",
        "dataset_dict = {\n",
        "    'train': '/content/drive/MyDrive/project/data/license_plates/archive/images/train_split',\n",
        "    'val': '/content/drive/MyDrive/project/data/license_plates/archive/images/val',\n",
        "    'test': '/content/drive/MyDrive/project/data/license_plates/archive/images/test',\n",
        "    'nc': 1,\n",
        "    'names': ['license_plate']\n",
        "}\n",
        "\n",
        "with open(dataset_yaml_path, 'w') as f:\n",
        "    yaml.dump(dataset_dict, f, default_flow_style=False)\n",
        "\n",
        "print(f\"dataset.yaml created at: {dataset_yaml_path}\")"
      ],
      "metadata": {
        "id": "bg06Mkx2COMn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}